# ProcessPulse - Complete Docker Deployment
# 
# DISK SPACE REQUIREMENTS:
# - Docker images: ~2.5 GB
# - AI Models (downloaded on first run):
#   - Chat model (llama3.1:8b): ~4.7 GB
#   - Embedding model (nomic-embed-text): ~275 MB
# - Total: ~7.5 GB minimum
#
# USAGE:
#   docker-compose up -d
#
# First run will take 5-15 minutes to download AI models.

version: '3.8'

services:
  # ===========================================
  # Frontend (React + nginx)
  # ===========================================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: processpulse-frontend
    ports:
      - "${FRONTEND_PORT:-80}:80"
    depends_on:
      backend:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - processpulse-network

  # ===========================================
  # Backend (FastAPI)
  # ===========================================
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: processpulse-backend
    environment:
      - DATABASE_URL=sqlite+aiosqlite:///./data/process_analyzer.db
      - OLLAMA_BASE_URL=http://ollama:11434
      - PERPLEXICA_BASE_URL=http://perplexica:3000
      - DEBUG=${DEBUG:-false}
    volumes:
      - processpulse-data:/app/data
    depends_on:
      ollama-init:
        condition: service_completed_successfully
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - processpulse-network

  # ===========================================
  # Ollama (Local AI)
  # ===========================================
  ollama:
    image: ollama/ollama:latest
    container_name: processpulse-ollama
    volumes:
      - ollama-models:/root/.ollama
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    restart: unless-stopped
    # Uncomment below for GPU support (requires nvidia-docker)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]
    networks:
      - processpulse-network

  # ===========================================
  # Ollama Model Initializer
  # Downloads required models on first run
  # ===========================================
  ollama-init:
    image: ollama/ollama:latest
    container_name: processpulse-ollama-init
    depends_on:
      - ollama
    volumes:
      - ollama-models:/root/.ollama
    environment:
      - OLLAMA_HOST=http://ollama:11434
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo "=========================================="
        echo "ProcessPulse Model Initializer"
        echo "=========================================="
        echo ""
        echo "Waiting for Ollama to be ready..."
        sleep 10
        
        # Check if Ollama is responding
        until curl -s http://ollama:11434/api/tags > /dev/null 2>&1; do
          echo "Waiting for Ollama..."
          sleep 5
        done
        echo "Ollama is ready!"
        echo ""
        
        # Pull chat model (~4.7 GB)
        echo "=========================================="
        echo "Downloading chat model: ${CHAT_MODEL:-llama3.1:8b}"
        echo "Size: ~4.7 GB - This may take 5-10 minutes..."
        echo "=========================================="
        curl -X POST http://ollama:11434/api/pull -d '{"name": "${CHAT_MODEL:-llama3.1:8b}"}'
        echo ""
        
        # Pull embedding model (~275 MB)
        echo "=========================================="
        echo "Downloading embedding model: ${EMBEDDING_MODEL:-nomic-embed-text}"
        echo "Size: ~275 MB"
        echo "=========================================="
        curl -X POST http://ollama:11434/api/pull -d '{"name": "${EMBEDDING_MODEL:-nomic-embed-text}"}'
        echo ""
        
        echo "=========================================="
        echo "All models downloaded successfully!"
        echo "=========================================="
        
        # List available models
        echo "Available models:"
        curl -s http://ollama:11434/api/tags | grep -o '"name":"[^"]*"' | cut -d'"' -f4
    networks:
      - processpulse-network

  # ===========================================
  # Perplexica (AI-Powered Web Search)
  # ===========================================
  perplexica-backend:
    image: ghcr.io/itzcrazy/perplexica-backend:main
    container_name: processpulse-perplexica-backend
    environment:
      - SEARXNG_API_URL=http://searxng:8080
      - OLLAMA_API_URL=http://ollama:11434
    depends_on:
      - ollama
      - searxng
    restart: unless-stopped
    networks:
      - processpulse-network

  perplexica:
    image: ghcr.io/itzcrazy/perplexica-frontend:main
    container_name: processpulse-perplexica
    environment:
      - NEXT_PUBLIC_API_URL=http://perplexica-backend:3001
      - NEXT_PUBLIC_WS_URL=ws://perplexica-backend:3001
    ports:
      - "${PERPLEXICA_PORT:-3000}:3000"
    depends_on:
      - perplexica-backend
    restart: unless-stopped
    networks:
      - processpulse-network

  # ===========================================
  # SearXNG (Search Engine for Perplexica)
  # ===========================================
  searxng:
    image: searxng/searxng:latest
    container_name: processpulse-searxng
    environment:
      - SEARXNG_BASE_URL=http://localhost:8080
    volumes:
      - searxng-data:/etc/searxng
    restart: unless-stopped
    networks:
      - processpulse-network

# ===========================================
# Persistent Volumes
# ===========================================
volumes:
  processpulse-data:
    name: processpulse-data
  ollama-models:
    name: processpulse-ollama-models
  searxng-data:
    name: processpulse-searxng-data

# ===========================================
# Network
# ===========================================
networks:
  processpulse-network:
    name: processpulse-network
    driver: bridge

